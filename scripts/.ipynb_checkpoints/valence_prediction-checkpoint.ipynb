{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valence Prediction Conclusions:\n",
    "\n",
    "### Tesing Gradient Boosting Regressors\n",
    "\n",
    "Not much gained or lost from increase in sample size. \n",
    "R2 error increased by .018 which is not too significant \n",
    "\n",
    "on sample size 500/genre and NO hyperparameter tuning (out of the box):\n",
    "- [GB] Mean Squared Error: 0.05264719893512396\n",
    "- [GB] R2: 0.08043425668821236\n",
    "\n",
    "on sample size 1687/genre with optimal hyperparamers: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}:\n",
    "- [GB] Mean Squared Error: 0.05200244352093515\n",
    "- [GB] R2: 0.09854691815352778\n",
    "\n",
    "on full data set with optimal hyperparamers:\n",
    "- [GB] Mean Squared Error: 0.05284822264086245\n",
    "- [GB] R2: 0.12264012250017176\n",
    "\n",
    "#### ** GB runs MUCH faster than RFreg and produces better r2 on the full data set\n",
    "\n",
    "---\n",
    "\n",
    "### Tesing Random Forest Regressors\n",
    "\n",
    "Not much gained or lost from increase in sample size. \n",
    "R2 error increased by .02 which is not too significant \n",
    "\n",
    "on sample size 500/genre with optimal hyperparamers:\n",
    "- [RF] Mean Squared Error: 0.05222244210798196\n",
    "- [RF] R2: 0.10795588207769391\n",
    "\n",
    "on sample size 1687/genre with optimal hyperparamers:\n",
    "- [RF] Mean Squared Error: 0.05101035414841959\n",
    "- [RF] R2: 0.1205852034338123\n",
    "\n",
    "on full data set with optimal hyperparamers:\n",
    "- [RF] Mean Squared Error: 0.05115798019890316\n",
    "- [RF] R2: 0.15070068589697727\n",
    "\n",
    "---\n",
    "\n",
    "### Issues:\n",
    "- stemming created gibberish\n",
    "- GridSearchCV takes 2+ hours to run (up to 4)\n",
    "\n",
    "---\n",
    "\n",
    "### Try:\n",
    "- turning valence into classification problem instead of regression\n",
    "    - round lable values to tens place and you'll have 10 classification categories \n",
    "- look at other regression metrics\n",
    "    - however r2 may not be good metric for this bc low correlation between variables\n",
    "    - functions ending with _score return a value to maximize, the higher the better.\n",
    "    - functions ending with _error or _loss return a value to minimize, the lower the better.\n",
    "- try lemming instead of stemming\n",
    "- try Word2Vec instead of tfidf\n",
    "- look into this for improving grid search https://scikit-learn.org/stable/modules/grid_search.html#grid-search \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleksandrageorgievska/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aleksandrageorgievska/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aleksandrageorgievska/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import pandas for data handling\n",
    "import pandas as pd\n",
    "\n",
    "# NLTK is our Natural-Language-Took-Kit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Libraries for helping us with strings\n",
    "import string\n",
    "# Regular Expression Library\n",
    "import re\n",
    "\n",
    "# Import text vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Import Regressor Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Import some ML helper function\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Import our metrics to evaluate our model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/labeled_lyrics_w_genres.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "(145250, 7)\n",
      "Pop          57357\n",
      "No_genre     42789\n",
      "Rock         26756\n",
      "Country       7440\n",
      "Rap           5959\n",
      "R&B           4773\n",
      "Non-Music      176\n",
      "Name: genre, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>No, no\\r\\nI ain't ever trapped out the bando\\r...</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>0.626</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>The drinks go down and smoke goes up, I feel m...</td>\n",
       "      <td>Live Till We Die</td>\n",
       "      <td>0.630</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>She don't live on planet Earth no more\\r\\nShe ...</td>\n",
       "      <td>The Otherside</td>\n",
       "      <td>0.240</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>Trippin' off that Grigio, mobbin', lights low\\...</td>\n",
       "      <td>Pinot</td>\n",
       "      <td>0.536</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>I see a midnight panther, so gallant and so br...</td>\n",
       "      <td>Shadows &amp; Diamonds</td>\n",
       "      <td>0.371</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1        artist  \\\n",
       "0           0             0  Elijah Blake   \n",
       "1           1             1  Elijah Blake   \n",
       "2           2             2  Elijah Blake   \n",
       "3           3             3  Elijah Blake   \n",
       "4           4             4  Elijah Blake   \n",
       "\n",
       "                                                 seq                song  \\\n",
       "0  No, no\\r\\nI ain't ever trapped out the bando\\r...            Everyday   \n",
       "1  The drinks go down and smoke goes up, I feel m...    Live Till We Die   \n",
       "2  She don't live on planet Earth no more\\r\\nShe ...       The Otherside   \n",
       "3  Trippin' off that Grigio, mobbin', lights low\\...               Pinot   \n",
       "4  I see a midnight panther, so gallant and so br...  Shadows & Diamonds   \n",
       "\n",
       "   label genre  \n",
       "0  0.626   R&B  \n",
       "1  0.630   Pop  \n",
       "2  0.240   R&B  \n",
       "3  0.536   R&B  \n",
       "4  0.371   R&B  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.isnull().sum().sum())\n",
    "print(df.duplicated().sum())\n",
    "print(df.shape)\n",
    "print(df.genre.value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing No_genre and Non-Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df[(df['genre'] == 'No_genre') | (df['genre'] == 'Non-Music')].index\n",
    "df.drop(df_dropped, inplace=True, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102285, 7)\n",
      "Pop        57357\n",
      "Rock       26756\n",
      "Country     7440\n",
      "Rap         5959\n",
      "R&B         4773\n",
      "Name: genre, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>No, no\\r\\nI ain't ever trapped out the bando\\r...</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>The drinks go down and smoke goes up, I feel m...</td>\n",
       "      <td>Live Till We Die</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>She don't live on planet Earth no more\\r\\nShe ...</td>\n",
       "      <td>The Otherside</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>Trippin' off that Grigio, mobbin', lights low\\...</td>\n",
       "      <td>Pinot</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>I see a midnight panther, so gallant and so br...</td>\n",
       "      <td>Shadows &amp; Diamonds</td>\n",
       "      <td>0.3710</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>I just want to ready your mind\\r\\n'Cause I'll ...</td>\n",
       "      <td>Uno</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Elis</td>\n",
       "      <td>Dieses ist lange her.\\r\\nDa ich deine schmalen...</td>\n",
       "      <td>Abendlied</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Elis</td>\n",
       "      <td>A child is born\\r\\nOut of the womb of a mother...</td>\n",
       "      <td>Child</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Elis</td>\n",
       "      <td>Out of the darkness you came \\r\\nYou looked so...</td>\n",
       "      <td>Come to Me</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Elis</td>\n",
       "      <td>Each night I lie in my bed \\r\\nAnd I think abo...</td>\n",
       "      <td>Do You Believe</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Elis</td>\n",
       "      <td>Nebel zieh'n gespentisch vor \\r\\nDer Sucher se...</td>\n",
       "      <td>Engel der Nacht</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Elis</td>\n",
       "      <td>I'm a lonely stranger \\r\\nIn this world of pai...</td>\n",
       "      <td>My Only Love</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>Elis</td>\n",
       "      <td>Schwere Tranen \\r\\nVergebens geweint \\r\\nRinne...</td>\n",
       "      <td>Sie Erfasst Mein Herz</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Elis</td>\n",
       "      <td>Come calm my anger\\n\\nOur love is like a perfe...</td>\n",
       "      <td>Anger</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>Elis</td>\n",
       "      <td>I was walking through the night\\nSuddenly I re...</td>\n",
       "      <td>Black Angel</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1        artist  \\\n",
       "0            0             0  Elijah Blake   \n",
       "1            1             1  Elijah Blake   \n",
       "2            2             2  Elijah Blake   \n",
       "3            3             3  Elijah Blake   \n",
       "4            4             4  Elijah Blake   \n",
       "5            5             5  Elijah Blake   \n",
       "7            7             7          Elis   \n",
       "8            8             8          Elis   \n",
       "9            9             9          Elis   \n",
       "10          10            10          Elis   \n",
       "11          11            11          Elis   \n",
       "12          12            12          Elis   \n",
       "13          13            13          Elis   \n",
       "14          14            14          Elis   \n",
       "15          15            15          Elis   \n",
       "\n",
       "                                                  seq                   song  \\\n",
       "0   No, no\\r\\nI ain't ever trapped out the bando\\r...               Everyday   \n",
       "1   The drinks go down and smoke goes up, I feel m...       Live Till We Die   \n",
       "2   She don't live on planet Earth no more\\r\\nShe ...          The Otherside   \n",
       "3   Trippin' off that Grigio, mobbin', lights low\\...                  Pinot   \n",
       "4   I see a midnight panther, so gallant and so br...     Shadows & Diamonds   \n",
       "5   I just want to ready your mind\\r\\n'Cause I'll ...                    Uno   \n",
       "7   Dieses ist lange her.\\r\\nDa ich deine schmalen...              Abendlied   \n",
       "8   A child is born\\r\\nOut of the womb of a mother...                  Child   \n",
       "9   Out of the darkness you came \\r\\nYou looked so...             Come to Me   \n",
       "10  Each night I lie in my bed \\r\\nAnd I think abo...         Do You Believe   \n",
       "11  Nebel zieh'n gespentisch vor \\r\\nDer Sucher se...        Engel der Nacht   \n",
       "12  I'm a lonely stranger \\r\\nIn this world of pai...           My Only Love   \n",
       "13  Schwere Tranen \\r\\nVergebens geweint \\r\\nRinne...  Sie Erfasst Mein Herz   \n",
       "14  Come calm my anger\\n\\nOur love is like a perfe...                  Anger   \n",
       "15  I was walking through the night\\nSuddenly I re...            Black Angel   \n",
       "\n",
       "     label genre  \n",
       "0   0.6260   R&B  \n",
       "1   0.6300   Pop  \n",
       "2   0.2400   R&B  \n",
       "3   0.5360   R&B  \n",
       "4   0.3710   R&B  \n",
       "5   0.3210   R&B  \n",
       "7   0.3330   Pop  \n",
       "8   0.5060   Pop  \n",
       "9   0.1790   Pop  \n",
       "10  0.2090   Pop  \n",
       "11  0.3210   Pop  \n",
       "12  0.2010   Pop  \n",
       "13  0.2180   Pop  \n",
       "14  0.3060   Pop  \n",
       "15  0.0958   Pop  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.genre.value_counts())\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data Cleaning (Text Pre Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. function that makes all text lowercase.\n",
    "def make_lowercase(test_string):\n",
    "    return test_string.lower()\n",
    "\n",
    "# 2. function that removes all punctuation. \n",
    "def remove_punc(test_string):\n",
    "    test_string = re.sub(r'[^\\w\\s]', '', test_string)\n",
    "    return test_string\n",
    "\n",
    "# 3. function that removes all stopwords.\n",
    "def remove_stopwords(test_string):\n",
    "    # Break the sentence down into a list of words\n",
    "    words = word_tokenize(test_string)\n",
    "    \n",
    "    # Make a list to append valid words into\n",
    "    valid_words = []\n",
    "    \n",
    "    # Loop through all the words\n",
    "    for word in words:\n",
    "        \n",
    "        # Check if word is not in stopwords. Stopwords was imported from nltk.corpus\n",
    "        if word not in stopwords:\n",
    "            \n",
    "            # If word not in stopwords, append to our valid_words\n",
    "            valid_words.append(word)\n",
    "\n",
    "    # Join the list of words together into a string\n",
    "    a_string = ' '.join(valid_words)\n",
    "\n",
    "    return a_string\n",
    "\n",
    "# 4. function to break words into their stem words\n",
    "def stem_words(a_string):\n",
    "    # Initalize our Stemmer\n",
    "    porter = PorterStemmer()\n",
    "    \n",
    "    # Break the sentence down into a list of words\n",
    "    words = word_tokenize(a_string)\n",
    "    \n",
    "    # Make a list to append valid words into\n",
    "    valid_words = []\n",
    "\n",
    "    # Loop through all the words\n",
    "    for word in words:\n",
    "        # Stem the word\n",
    "        stemmed_word = porter.stem(word) #from nltk.stem import PorterStemmer\n",
    "        \n",
    "        # Append stemmed word to our valid_words\n",
    "        valid_words.append(stemmed_word)\n",
    "        \n",
    "    # Join the list of words together into a string\n",
    "    a_string = ' '.join(valid_words)\n",
    "\n",
    "    return a_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline function \n",
    "\n",
    "def text_processing_pipeline(a_string):\n",
    "    a_string = make_lowercase(a_string)\n",
    "    a_string = remove_punc(a_string)\n",
    "    #a_string = stem_words(a_string) #removing stem_words for now because making lyrics gibberish\n",
    "    a_string = remove_stopwords(a_string)\n",
    "    return a_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing pipeline \n",
    "\n",
    "df['seq_clean'] = df['seq'].apply(text_processing_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "      <th>seq_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>No, no\\r\\nI ain't ever trapped out the bando\\r...</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>0.626</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>aint ever trapped bando oh lord dont get wrong...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1        artist  \\\n",
       "0           0             0  Elijah Blake   \n",
       "\n",
       "                                                 seq      song  label genre  \\\n",
       "0  No, no\\r\\nI ain't ever trapped out the bando\\r...  Everyday  0.626   R&B   \n",
       "\n",
       "                                           seq_clean  \n",
       "0  aint ever trapped bando oh lord dont get wrong...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['seq_clean'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling smaller batches from dataframe for faster testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to randomly sample n values from each genre for smaller random forest testing\n",
    "\n",
    "def genre_sample(dataframe, k):\n",
    "    #make an empty dataframe\n",
    "    df_genre_sample = pd.DataFrame(columns = ['Unnamed: 0', 'artist', 'seq', 'song', 'label', 'genre', 'seq_clean'])\n",
    "    \n",
    "    genres = ['R&B', 'Pop', 'Rap', 'Rock', 'Country']\n",
    "    for genre in genres:\n",
    "         df_genre_sample = df_genre_sample.append((dataframe[dataframe[\"genre\"]==genre].sample(n=k)))\n",
    "    \n",
    "    return df_genre_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 8)\n",
      "Rap        500\n",
      "Pop        500\n",
      "R&B        500\n",
      "Country    500\n",
      "Rock       500\n",
      "Name: genre, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "      <th>seq_clean</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109296</th>\n",
       "      <td>1396</td>\n",
       "      <td>Muddy Waters</td>\n",
       "      <td>Well, it gettin'\\nLate on into the evenin' and...</td>\n",
       "      <td>Feel Like Going Home</td>\n",
       "      <td>0.185</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>well gettin late evenin feel like like blowin ...</td>\n",
       "      <td>60423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85479</th>\n",
       "      <td>2479</td>\n",
       "      <td>Monifah</td>\n",
       "      <td>I want you, I want you, I want you, I want you...</td>\n",
       "      <td>You</td>\n",
       "      <td>0.833</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>want want want want sun dont shine brighten da...</td>\n",
       "      <td>70912.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126356</th>\n",
       "      <td>1856</td>\n",
       "      <td>Luther Vandross</td>\n",
       "      <td>What's your name?\\r\\nGirl what's your number?\\...</td>\n",
       "      <td>For the Sweetness of Your Love</td>\n",
       "      <td>0.936</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>whats name girl whats number think fell love f...</td>\n",
       "      <td>121952.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44834</th>\n",
       "      <td>44834</td>\n",
       "      <td>Timbaland</td>\n",
       "      <td>Is it going, is it going, is it going, is it g...</td>\n",
       "      <td>Give It to Me</td>\n",
       "      <td>0.815</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>going going going going dont know youre lookin...</td>\n",
       "      <td>154408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79558</th>\n",
       "      <td>708</td>\n",
       "      <td>Muddy Waters</td>\n",
       "      <td>Want you to rock me baby, rock me all night lo...</td>\n",
       "      <td>Rock Me [#]</td>\n",
       "      <td>0.633</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>want rock baby rock night long want rock baby ...</td>\n",
       "      <td>60495.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           artist  \\\n",
       "109296       1396     Muddy Waters   \n",
       "85479        2479          Monifah   \n",
       "126356       1856  Luther Vandross   \n",
       "44834       44834        Timbaland   \n",
       "79558         708     Muddy Waters   \n",
       "\n",
       "                                                      seq  \\\n",
       "109296  Well, it gettin'\\nLate on into the evenin' and...   \n",
       "85479   I want you, I want you, I want you, I want you...   \n",
       "126356  What's your name?\\r\\nGirl what's your number?\\...   \n",
       "44834   Is it going, is it going, is it going, is it g...   \n",
       "79558   Want you to rock me baby, rock me all night lo...   \n",
       "\n",
       "                                  song  label genre  \\\n",
       "109296            Feel Like Going Home  0.185   R&B   \n",
       "85479                              You  0.833   R&B   \n",
       "126356  For the Sweetness of Your Love  0.936   R&B   \n",
       "44834                    Give It to Me  0.815   R&B   \n",
       "79558                      Rock Me [#]  0.633   R&B   \n",
       "\n",
       "                                                seq_clean  Unnamed: 0.1  \n",
       "109296  well gettin late evenin feel like like blowin ...       60423.0  \n",
       "85479   want want want want sun dont shine brighten da...       70912.0  \n",
       "126356  whats name girl whats number think fell love f...      121952.0  \n",
       "44834   going going going going dont know youre lookin...      154408.0  \n",
       "79558   want rock baby rock night long want rock baby ...       60495.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling from the dataframe, k is the # of samples from each genre\n",
    "\n",
    "df_sampled = genre_sample(df, k=500)\n",
    "print(df_sampled.shape)\n",
    "\n",
    "#checking correct amounts of samples per genre were obtained\n",
    "print(df_sampled.genre.value_counts())\n",
    "df_sampled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Regression Models for label prediction:\n",
    "- label = float scale (0-1) which signifies valence \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using the sampled dataset for faster testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampled = df_sampled['seq_clean'].values\n",
    "\n",
    "y_sampled = df_sampled['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_sampled, y_sampled, \n",
    "                                                                             test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1675, 19224) <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train_sample)\n",
    "\n",
    "X_train_sample = vectorizer.transform(X_train_sample)\n",
    "X_test_sample = vectorizer.transform(X_test_sample)\n",
    "\n",
    "print(X_train_sample.shape, type(X_train_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the best parameters for RandomForestRegressor\n",
    "\n",
    "param_grid = {'n_estimators': [100, 1000],\n",
    "              'scoring': ['max_error','neg_root_mean_squared_error']\n",
    "             }\n",
    "\n",
    "# there are more parameters to test but I was getting errors and need to investigate more\n",
    "\n",
    "# param_grid = {'criterion': ['squared_error', 'absolute_error', 'poisson'],\n",
    "#               'n_estimators': [10, 50, 100, 500, 1000], \n",
    "#               'max_depth': [2, 4, 8, 16, 32, 64], \n",
    "#               'min_samples_leaf': [1, 10, 25, 50],\n",
    "#               'bootstrap': [True, False],\n",
    "#               'min_samples_split': [0, 2, 4, 8, 16, 32]\n",
    "#              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Do not run the next cell unless you have 2+ hours to kill*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Grid Search...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter scoring for estimator RandomForestRegressor(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/aleksandrageorgievska/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/Users/aleksandrageorgievska/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/aleksandrageorgievska/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/aleksandrageorgievska/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/aleksandrageorgievska/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/aleksandrageorgievska/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 520, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/Users/aleksandrageorgievska/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\", line 249, in set_params\n    raise ValueError('Invalid parameter %s for estimator %s. '\nValueError: Invalid parameter scoring for estimator RandomForestRegressor(). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-af7a899af7d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#    variable 'rf_grid_search'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrf_grid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter scoring for estimator RandomForestRegressor(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# set \"n_jobs= -1\" in gridsearchcv, tells python to use all processers/paralleization \n",
    "\n",
    "print('Running Grid Search...')\n",
    "\n",
    "# 1. Create a RandomForestRegressor model object without supplying arguments. \n",
    "\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# 2. Run a Grid Search with 3-fold cross-validation and assign the output to the object 'rf_grid'.\n",
    "#    * Pass the model and the parameter grid to GridSearchCV()\n",
    "#    * Set the number of folds to 3\n",
    "#    * Specify the scoring method\n",
    "\n",
    "rf_grid = GridSearchCV(n_jobs = -1, estimator=rf_regressor, param_grid = param_grid, cv=3) \n",
    "\n",
    "# 3. Fit the model (use the 'grid' variable) on the training data and assign the fitted model to the \n",
    "#    variable 'rf_grid_search'\n",
    "\n",
    "rf_grid_search = rf_grid.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-491d4faa16a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "GridSearchCV.get_params('self').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding best parameters for the Random Forest Regressor\n",
    "\n",
    "best_score = rf_grid_search.best_score_\n",
    "print(\"The best score is: \", best_score)\n",
    "\n",
    "rf_best_params = rf_grid_search.best_params_\n",
    "print(\"The best params is: \", rf_best_params)\n",
    "\n",
    "# conclusion was n_estimators=1000, bootstrap = True are best hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal Hyperparameters for RandomForestRegressor based on GridSearchCV\n",
    "\n",
    "rf_model1 = RandomForestRegressor(n_estimators=1000, bootstrap = True)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "rf_model1.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample_pred = rf_model1.predict(X_test_sample)\n",
    "\n",
    "rf_mse = mean_squared_error(y_test_sample, y_sample_pred)\n",
    "rf_r2 = r2_score(y_test_sample, y_sample_pred)\n",
    "\n",
    "print('on sample size of 500/genre with optimal hyperparameters:')\n",
    "print('[RF] Mean Squared Error: {0}'.format(rf_mse))\n",
    "print('[RF] R2: {0}'.format(rf_r2))\n",
    "\n",
    "# on sample size of 500/genre with optimal hyperparameters:\n",
    "# - [RF] Mean Squared Error: 0.05222244210798196\n",
    "# - [RF] R2: 0.10795588207769391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the predictions of the model with NEW unseen text (not part of testing set)\n",
    "\n",
    "def rgrg_string_test(lyrics):\n",
    "    new_lyrics = text_processing_pipeline(lyrics)\n",
    "    print(\"the processed lyrics are: \", new_lyrics)\n",
    "    \n",
    "    new_text_vectorized = vectorizer.transform([new_lyrics])\n",
    "    \n",
    "    value = rf_model1.predict(new_text_vectorized)\n",
    "    print(\"Random Forest Regressor model gives a value of: \", value)\n",
    "    if(value < .50):\n",
    "        print(\"which is negative\")\n",
    "    else: \n",
    "        print(\"which is positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text1 = \"Hit me baby one more time my lonliness is killing me and I must confess I still believe\"\n",
    "test_text2 = \"Oh, baby, when you talk like that You make a woman go mad So be wise and keep on Reading the signs of my body\"\n",
    "test_text3 = \"looking out on the pouring rain I used to feel so uninspired\"\n",
    "test_text4 = \"Girl put your record on tell me your favorite song just go ahead let your hair down\"\n",
    "\n",
    "rgrg_string_test(test_text1)\n",
    "print('\\n')\n",
    "rgrg_string_test(test_text2)\n",
    "print('\\n')\n",
    "rgrg_string_test(test_text3)\n",
    "print('\\n')\n",
    "rgrg_string_test(test_text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Larger RF Test on 1687 samples from each Genre\n",
    "\n",
    "- to-do: break this testing out into a function instead of repeating code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling from the dataframe, k is 1687 which is the max number of samples from R&B the smallest Genre pool \n",
    "\n",
    "df_sampled2 = genre_sample(df, k=1687)\n",
    "print(df_sampled2.shape)\n",
    "df_sampled2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking correct amounts of samples per genre were obtained\n",
    "\n",
    "df_sampled2.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampled2 = df_sampled2['seq_clean'].values\n",
    "\n",
    "y_sampled2 = df_sampled2['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample2, X_test_sample2, y_train_sample2, y_test_sample2 = train_test_split(X_sampled2, y_sampled2, \n",
    "                                                                             test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer()\n",
    "vectorizer2.fit(X_train_sample2)\n",
    "\n",
    "X_train_sample2 = vectorizer2.transform(X_train_sample2)\n",
    "X_test_sample2 = vectorizer2.transform(X_test_sample2)\n",
    "\n",
    "print(X_train_sample2.shape, type(X_train_sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal Hyperparameters for RandomForestRegressor based on GridSearchCV\n",
    "\n",
    "rf_model2 = RandomForestRegressor(n_estimators=1000, bootstrap = True)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "rf_model2.fit(X_train_sample2, y_train_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample_pred2 = rf_model2.predict(X_test_sample2)\n",
    "y_sample_pred2\n",
    "\n",
    "rf_mse2 = mean_squared_error(y_test_sample2, y_sample_pred2)\n",
    "rf_r2_2 = r2_score(y_test_sample2, y_sample_pred2)\n",
    "\n",
    "print('on sample size of 1687/genre  with optimal hyperparameters:')\n",
    "print('[RF] Mean Squared Error: {0}'.format(rf_mse2))\n",
    "print('[RF] R2: {0}'.format(rf_r2_2))\n",
    "\n",
    "# on sample size 1687/genre with optimal hyperprameters:\n",
    "# - [RF] Mean Squared Error: 0.05101035414841959\n",
    "# - [RF] R2: 0.1205852034338123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion on tesing Random Forest Regressors\n",
    "\n",
    "Not much gained or lost from increase in sample size. \n",
    "R2 error increased by .02 which is not too significant \n",
    "\n",
    "on sample size 500/genre with optimal hyperparameters:\n",
    "- [RF] Mean Squared Error: 0.05222244210798196\n",
    "- [RF] R2: 0.10795588207769391\n",
    "\n",
    "on sample size 1687/genre with optimal hyperprameters:\n",
    "- [RF] Mean Squared Error: 0.05101035414841959\n",
    "- [RF] R2: 0.1205852034338123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running RF Test on Full Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 3. Fit your vectorizer using your X data\n",
    "# This makes your vocab matrix\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# 4. Transform your X data using your fitted vectorizer. \n",
    "# This transforms your documents into vectors.\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train.shape, type(X))\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal Hyperparameters for RandomForestRegressor based on GridSearchCV\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=1000, bootstrap = True)\n",
    "\n",
    "# 2. Fit the model to the training data below\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, y_pred)\n",
    "rf_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('on full data set with optimal hyperparameters:')\n",
    "print('[RF] Mean Squared Error: {0}'.format(rf_mse))\n",
    "print('[RF] R2: {0}'.format(rf_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end of RF testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor\n",
    "Gradient boosting is a technique for repeatedly adding decision trees so that the next decision tree corrects the previous decision tree error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling from the dataframe, k is the # of samples from each genre\n",
    "\n",
    "df_sampled3 = genre_sample(df, k=500)\n",
    "print(df_sampled3.shape)\n",
    "df_sampled3.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking correct amounts of samples per genre were obtained\n",
    "df_sampled3.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampled3 = df_sampled3['seq_clean'].values\n",
    "y_sampled3 = df_sampled3['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample3, X_test_sample3, y_train_sample3, y_test_sample3 = train_test_split(X_sampled3, y_sampled3, \n",
    "                                                                                    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer3 = TfidfVectorizer()\n",
    "vectorizer3.fit(X_train_sample3)\n",
    "\n",
    "X_train_sample3 = vectorizer3.transform(X_train_sample3)\n",
    "X_test_sample3 = vectorizer3.transform(X_test_sample3)\n",
    "\n",
    "print(X_train_sample3.shape, type(X_train_sample3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.fit(X_train_sample3, y_train_sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sample3 = gb.predict(X_test_sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_mse = mean_squared_error(y_test_sample3, y_pred_sample3)\n",
    "gb_r2 = r2_score(y_test_sample3, y_pred_sample3)\n",
    "\n",
    "print('For a sample size of 500 and NO hyperparameter tuning:')\n",
    "print('[GB] Mean Squared Error: {0}'.format(gb_mse))\n",
    "print('[GB] R2: {0}'.format(gb_r2))\n",
    "print(\"\\n Gradient Boosting Regressor produces same MSE as Random Forest but r2 has improved by .05\")\n",
    "\n",
    "# For a sample size of 500 and NO hyperparameter tuning:\n",
    "# [GB] Mean Squared Error: 0.05264719893512396\n",
    "# [GB] R2: 0.08043425668821236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning of Gradiet Boosting Regressor with GridSearchCV\n",
    "- need to run overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_grid= {'n_estimators': [100, 1000, 1500],\n",
    "                'learning_rate' : [0.1, 0.3, 0.5],\n",
    "                'max_depth': [3, 8, 16, 32]\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Do not run the next cell unless you have 2 hours to kill*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running Grid Search ... \")\n",
    "\n",
    "gb_regressor = GradientBoostingRegressor()\n",
    "\n",
    "gb_grid = GridSearchCV(n_jobs = -1, estimator = gb_regressor, param_grid= gb_param_grid, cv=3, scoring= 'mse')\n",
    "\n",
    "print(\"Running the fit..\")\n",
    "\n",
    "gb_grid_search = gb_grid.fit(X_train_sample3, y_train_sample3)\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "best_score3 = gb_grid_search.best_score_\n",
    "print(\"The best score is: \", best_score3)\n",
    "\n",
    "gb_best_params = gb_grid_search.best_params_\n",
    "print(\"The best parameters are: \", gb_best_params)\n",
    "\n",
    "# The best score is:  0.07331262579138897\n",
    "# The best parameters are:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Larger GB Test on 1687 samples from each Genre\n",
    "### with optimized hyper parameters {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling from the dataframe, k is 1687 which is the max number of samples from R&B the smallest Genre pool \n",
    "\n",
    "df_sampled4 = genre_sample(df, k=1687)\n",
    "print(df_sampled4.shape)\n",
    "df_sampled4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking correct amounts of samples per genre were obtained\n",
    "\n",
    "df_sampled4.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampled4 = df_sampled4['seq_clean'].values\n",
    "\n",
    "y_sampled4 = df_sampled4['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample4, X_test_sample4, y_train_sample4, y_test_sample4 = train_test_split(X_sampled4, y_sampled4, \n",
    "                                                                                    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer4 = TfidfVectorizer()\n",
    "vectorizer4.fit(X_train_sample4)\n",
    "\n",
    "X_train_sample4 = vectorizer4.transform(X_train_sample4)\n",
    "X_test_sample4 = vectorizer4.transform(X_test_sample4)\n",
    "\n",
    "print(X_train_sample4.shape, type(X_train_sample4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb2 = GradientBoostingRegressor(learning_rate=0.1, max_depth=3, n_estimators= 100)\n",
    "gb2.fit(X_train_sample4, y_train_sample4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sample4 = gb2.predict(X_test_sample4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_mse2 = mean_squared_error(y_test_sample4, y_pred_sample4)\n",
    "gb_r2_2 = r2_score(y_test_sample4, y_pred_sample4)\n",
    "\n",
    "print('For a sample size of 1687 and optimal hyperparameters:')\n",
    "print('[GB] Mean Squared Error: {0}'.format(gb_mse2))\n",
    "print('[GB] R2: {0}'.format(gb_r2_2))\n",
    "\n",
    "# For a sample size of 1687 and optimal hyperparameters:\n",
    "# [GB] Mean Squared Error: 0.05200244352093515\n",
    "# [GB] R2: 0.09854691815352778"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running GB on full data set with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 3. Fit your vectorizer using your X data\n",
    "# This makes your vocab matrix\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# 4. Transform your X data using your fitted vectorizer. \n",
    "# This transforms your documents into vectors.\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train.shape, type(X))\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb3 = GradientBoostingRegressor()\n",
    "gb3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb3.predict(X_test)\n",
    "gb3_mse = mean_squared_error(y_test, y_pred)\n",
    "gb3_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('On the full data set and optimal hyperparameter tuning:')\n",
    "print('[GB] Mean Squared Error: {0}'.format(gb3_mse))\n",
    "print('[GB] R2: {0}'.format(gb3_r2))\n",
    "print(\"\\n ...\")\n",
    "\n",
    "# On the full data set and optimal hyperparameter tuning:\n",
    "# [GB] Mean Squared Error: 0.05284822264086245\n",
    "# [GB] R2: 0.12264012250017176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion on tesing Gradient Boosting Regressors\n",
    "\n",
    "Not much gained or lost from increase in sample size. \n",
    "R2 error increased by .018 which is not too significant \n",
    "\n",
    "on sample size 500/genre and NO hyperparameter tuning:\n",
    "- [GB] Mean Squared Error: 0.05264719893512396\n",
    "- [GB] R2: 0.08043425668821236\n",
    "\n",
    "on sample size 1687/genre with optimal hyperparamers: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}:\n",
    "- [GB] Mean Squared Error: 0.05200244352093515\n",
    "- [GB] R2: 0.09854691815352778\n",
    "\n",
    "on full data set with optimal hyperparamers:\n",
    "- [GB] Mean Squared Error: 0.05284822264086245\n",
    "- [GB] R2: 0.12264012250017176\n",
    "\n",
    "** GB runs MUCH faster than RFreg and produces better r2 on the full data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "copied from previous cells for comparisson: \n",
    "\n",
    "# conclusion on tesing Random Forest Regressors\n",
    "\n",
    "Not much gained or lost from increase in sample size. \n",
    "R2 error increased by .02 which is not too significant \n",
    "\n",
    "on sample size 500/genre with optimal hyperparamers:\n",
    "- [RF] Mean Squared Error: 0.05222244210798196\n",
    "- [RF] R2: 0.10795588207769391\n",
    "\n",
    "on sample size 1687/genre with optimal hyperparamers:\n",
    "- [RF] Mean Squared Error: 0.05101035414841959\n",
    "- [RF] R2: 0.1205852034338123\n",
    "\n",
    "on full data set with optimal hyperparamers:\n",
    "- [RF] Mean Squared Error: 0.05115798019890316\n",
    "- [RF] R2: 0.15070068589697727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
