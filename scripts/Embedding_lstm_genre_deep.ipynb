{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d92550f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression as log \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn import metrics    \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b1411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf99d4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop        57357\n",
       "Rock       26756\n",
       "Country     7440\n",
       "Rap         5959\n",
       "R&B         4773\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labeled_lyrics_w_genres.csv')\n",
    "df.head()\n",
    "\n",
    "df = df.drop(columns = ['Unnamed: 0','Unnamed: 0.1'],axis = 1)\n",
    "\n",
    "df_dropped = df[(df['genre'] == 'No_genre') | (df['genre'] == 'Non-Music')].index\n",
    "df.drop(df_dropped, inplace=True, axis='index')\n",
    "\n",
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55c69b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = \"\"\n",
    "\n",
    "cond = df['genre'] == 'Pop'\n",
    "df_pop = df[cond]\n",
    "df_pop = df_pop[0:4000]\n",
    "\n",
    "cond = df['genre'] == 'Rock'\n",
    "df_rock = df[cond]\n",
    "df_rock = df_rock[0:4000]\n",
    "df_rock.shape\n",
    "\n",
    "cond = df['genre'] == 'Country'\n",
    "df_country = df[cond]\n",
    "df_country = df_country[0:4000]\n",
    "df_country.shape\n",
    "\n",
    "cond = df['genre'] == 'Rap'\n",
    "df_rap = df[cond]\n",
    "df_rap = df_rap[0:4000]\n",
    "df_rap.shape\n",
    "\n",
    "cond = df['genre'] == 'R&B'\n",
    "df_r_b = df[cond]\n",
    "df_r_b = df_r_b[0:4000]\n",
    "df_r_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfc7ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop        4000\n",
       "Rock       4000\n",
       "Country    4000\n",
       "Rap        4000\n",
       "R&B        4000\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_pop, df_rock, df_country, df_rap, df_r_b], axis = 0)\n",
    "\n",
    "df_balanced['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779a51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove numbers\n",
    "def remove_numbers(input):\n",
    "    input = word_tokenize(input)\n",
    "    without_sw = [word for word in input \n",
    "                  if word.isalpha()]\n",
    "    return ' '.join(without_sw)\n",
    "\n",
    "# 1. function that makes all text lowercase.\n",
    "def make_lowercase(test_string):\n",
    "    return test_string.lower()\n",
    "\n",
    "# 2. function that removes all punctuation. \n",
    "def remove_punc(test_string):\n",
    "    test_string = re.sub(r'[^\\w\\s]', '', test_string)\n",
    "    return test_string\n",
    "\n",
    "# 3. function that removes all stopwords.\n",
    "def remove_sw(input):\n",
    "    input = word_tokenize(input)\n",
    "    without_sw = [word for word in input \n",
    "                  if word not in stopwords]\n",
    "    return ' '.join(without_sw)\n",
    "\n",
    "# 4. function to break words into their stem words\n",
    "def stem_words(input):\n",
    "    stemming = PorterStemmer()\n",
    "    tokenized_words = word_tokenize(input)\n",
    "    \n",
    "    stemmed_words = [stemming.stem(word) for word in tokenized_words]\n",
    "    return ' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c07d0c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "\n",
    "def text_processing_pipeline(a_string):\n",
    "    a_string = make_lowercase(a_string)\n",
    "    a_string = remove_numbers(a_string)\n",
    "    a_string = remove_punc(a_string)\n",
    "    a_string = remove_sw(a_string)\n",
    "    #a_string = stem_words(a_string)\n",
    "    return a_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0444cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['seq_clean'] = df_balanced['seq'].apply(lambda x: text_processing_pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "065e8c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "      <th>seq_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>The drinks go down and smoke goes up, I feel m...</td>\n",
       "      <td>Live Till We Die</td>\n",
       "      <td>0.630</td>\n",
       "      <td>Pop</td>\n",
       "      <td>drinks go smoke goes feel got let go cares get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Elis</td>\n",
       "      <td>Dieses ist lange her.\\r\\nDa ich deine schmalen...</td>\n",
       "      <td>Abendlied</td>\n",
       "      <td>0.333</td>\n",
       "      <td>Pop</td>\n",
       "      <td>dieses ist lange da ich deine schmalen hande n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elis</td>\n",
       "      <td>A child is born\\r\\nOut of the womb of a mother...</td>\n",
       "      <td>Child</td>\n",
       "      <td>0.506</td>\n",
       "      <td>Pop</td>\n",
       "      <td>child born womb mother want happened night dru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Elis</td>\n",
       "      <td>Out of the darkness you came \\r\\nYou looked so...</td>\n",
       "      <td>Come to Me</td>\n",
       "      <td>0.179</td>\n",
       "      <td>Pop</td>\n",
       "      <td>darkness came looked tired sad asked answered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Elis</td>\n",
       "      <td>Each night I lie in my bed \\r\\nAnd I think abo...</td>\n",
       "      <td>Do You Believe</td>\n",
       "      <td>0.209</td>\n",
       "      <td>Pop</td>\n",
       "      <td>night lie bed think oh dark friend give answer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                                seq  \\\n",
       "1   Elijah Blake  The drinks go down and smoke goes up, I feel m...   \n",
       "7           Elis  Dieses ist lange her.\\r\\nDa ich deine schmalen...   \n",
       "8           Elis  A child is born\\r\\nOut of the womb of a mother...   \n",
       "9           Elis  Out of the darkness you came \\r\\nYou looked so...   \n",
       "10          Elis  Each night I lie in my bed \\r\\nAnd I think abo...   \n",
       "\n",
       "                song  label genre  \\\n",
       "1   Live Till We Die  0.630   Pop   \n",
       "7          Abendlied  0.333   Pop   \n",
       "8              Child  0.506   Pop   \n",
       "9         Come to Me  0.179   Pop   \n",
       "10    Do You Believe  0.209   Pop   \n",
       "\n",
       "                                            seq_clean  \n",
       "1   drinks go smoke goes feel got let go cares get...  \n",
       "7   dieses ist lange da ich deine schmalen hande n...  \n",
       "8   child born womb mother want happened night dru...  \n",
       "9   darkness came looked tired sad asked answered ...  \n",
       "10  night lie bed think oh dark friend give answer...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "535ac026",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced.seq_clean.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4742ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "502d8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(X, vector_size = 250, sg=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e56e899f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248207082, 281636700)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.train(X, total_examples=20000, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2106a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f9e3de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blaring', 0.3584658205509186),\n",
       " ('outshine', 0.33836624026298523),\n",
       " ('tater', 0.33717799186706543),\n",
       " ('maddening', 0.33615100383758545),\n",
       " ('egypt', 0.3255713880062103),\n",
       " ('plantin', 0.32503318786621094),\n",
       " ('twang', 0.3224688768386841),\n",
       " ('password', 0.31763532757759094),\n",
       " ('allowing', 0.3130062222480774),\n",
       " ('geordie', 0.3123916983604431)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(positive ='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdf4e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_words = list(word2vec_model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a45fb17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40350144",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_words = list(word2vec_model.wv.key_to_index)\n",
    "def lyric_vector(tokens, size):\n",
    "    sent = np.zeros(250)\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word in w2v_words:\n",
    "            vec = word2vec_model.wv[word]\n",
    "            sent += vec\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "        sent /= count\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "307a82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = []\n",
    "for sent in X:\n",
    "    sentence = lyric_vector(sent, 200)\n",
    "    vector.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffe74dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003442</td>\n",
       "      <td>-0.009845</td>\n",
       "      <td>0.033642</td>\n",
       "      <td>0.017867</td>\n",
       "      <td>-0.108870</td>\n",
       "      <td>0.080865</td>\n",
       "      <td>-0.016341</td>\n",
       "      <td>0.127219</td>\n",
       "      <td>-0.008023</td>\n",
       "      <td>0.064092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080286</td>\n",
       "      <td>-0.046972</td>\n",
       "      <td>0.109665</td>\n",
       "      <td>-0.070063</td>\n",
       "      <td>0.022983</td>\n",
       "      <td>0.204102</td>\n",
       "      <td>-0.211368</td>\n",
       "      <td>0.015924</td>\n",
       "      <td>0.075099</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255161</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>-0.141956</td>\n",
       "      <td>0.126649</td>\n",
       "      <td>-0.660588</td>\n",
       "      <td>0.432395</td>\n",
       "      <td>0.049746</td>\n",
       "      <td>0.324717</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490461</td>\n",
       "      <td>-0.639241</td>\n",
       "      <td>-0.026243</td>\n",
       "      <td>0.107472</td>\n",
       "      <td>0.516244</td>\n",
       "      <td>0.618618</td>\n",
       "      <td>-0.852951</td>\n",
       "      <td>-0.224987</td>\n",
       "      <td>0.202187</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059246</td>\n",
       "      <td>0.086929</td>\n",
       "      <td>-0.028027</td>\n",
       "      <td>0.117113</td>\n",
       "      <td>-0.130827</td>\n",
       "      <td>0.086468</td>\n",
       "      <td>0.168874</td>\n",
       "      <td>0.176982</td>\n",
       "      <td>0.040304</td>\n",
       "      <td>0.100041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144587</td>\n",
       "      <td>0.103171</td>\n",
       "      <td>0.063966</td>\n",
       "      <td>-0.039830</td>\n",
       "      <td>-0.011357</td>\n",
       "      <td>0.169608</td>\n",
       "      <td>-0.010939</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>-0.156405</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040458</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.085805</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>-0.076782</td>\n",
       "      <td>0.055943</td>\n",
       "      <td>0.112457</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>0.048217</td>\n",
       "      <td>-0.027759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080867</td>\n",
       "      <td>0.081536</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>-0.018395</td>\n",
       "      <td>0.039758</td>\n",
       "      <td>0.277116</td>\n",
       "      <td>-0.085474</td>\n",
       "      <td>-0.048438</td>\n",
       "      <td>0.066239</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079064</td>\n",
       "      <td>-0.127495</td>\n",
       "      <td>-0.035198</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>-0.217552</td>\n",
       "      <td>0.071098</td>\n",
       "      <td>0.105536</td>\n",
       "      <td>0.128783</td>\n",
       "      <td>0.083611</td>\n",
       "      <td>-0.024084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098803</td>\n",
       "      <td>-0.053946</td>\n",
       "      <td>0.058641</td>\n",
       "      <td>0.017946</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>0.246829</td>\n",
       "      <td>-0.046775</td>\n",
       "      <td>-0.025265</td>\n",
       "      <td>0.057481</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.003442 -0.009845  0.033642  0.017867 -0.108870  0.080865 -0.016341   \n",
       "1  0.255161  0.016113 -0.141956  0.126649 -0.660588  0.432395  0.049746   \n",
       "2  0.059246  0.086929 -0.028027  0.117113 -0.130827  0.086468  0.168874   \n",
       "3  0.040458  0.007651  0.085805  0.007954 -0.076782  0.055943  0.112457   \n",
       "4  0.079064 -0.127495 -0.035198  0.046875 -0.217552  0.071098  0.105536   \n",
       "\n",
       "          7         8         9  ...       241       242       243       244  \\\n",
       "0  0.127219 -0.008023  0.064092  ... -0.080286 -0.046972  0.109665 -0.070063   \n",
       "1  0.324717  0.276112  0.297900  ... -0.490461 -0.639241 -0.026243  0.107472   \n",
       "2  0.176982  0.040304  0.100041  ... -0.144587  0.103171  0.063966 -0.039830   \n",
       "3 -0.001349  0.048217 -0.027759  ... -0.080867  0.081536  0.005493 -0.018395   \n",
       "4  0.128783  0.083611 -0.024084  ... -0.098803 -0.053946  0.058641  0.017946   \n",
       "\n",
       "        245       246       247       248       249  genre  \n",
       "0  0.022983  0.204102 -0.211368  0.015924  0.075099    R&B  \n",
       "1  0.516244  0.618618 -0.852951 -0.224987  0.202187    Pop  \n",
       "2 -0.011357  0.169608 -0.010939  0.126084 -0.156405    R&B  \n",
       "3  0.039758  0.277116 -0.085474 -0.048438  0.066239    R&B  \n",
       "4 -0.015124  0.246829 -0.046775 -0.025265  0.057481    R&B  \n",
       "\n",
       "[5 rows x 251 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_vector = pd.DataFrame(vector)\n",
    "lyric_vector['genre'] = pd.DataFrame(df['genre'])\n",
    "lyric_vector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b0f65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8237ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88cf6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df = df_balanced.sample(frac=1)\n",
    "labelencoder = LabelEncoder()\n",
    "df['genre'] = labelencoder.fit_transform(df['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a9088c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['seq_clean']\n",
    "\n",
    "y = df['genre'].values\n",
    "\n",
    "y = to_categorical( y )\n",
    "X_text = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d13177b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(num_words\u001b[38;5;241m=\u001b[39mmax_words)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Fit the tokenizer\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_on_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create the sequences for each sentence, basically turning each word into its index position\u001b[39;00m\n\u001b[0;32m     11\u001b[0m sequences \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\text.py:293\u001b[0m, in \u001b[0;36mTokenizer.fit_on_texts\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 293\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[43mtext_to_word_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m            \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    300\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\text.py:74\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[1;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a text to a sequence of words (or tokens).\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03mDeprecated: `tf.keras.preprocessing.text.text_to_word_sequence` does not\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    A list of words (or tokens).\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[1;32m---> 74\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[43minput_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     76\u001b[0m translate_dict \u001b[38;5;241m=\u001b[39m {c: split \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m filters}\n\u001b[0;32m     77\u001b[0m translate_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(translate_dict)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# Limiting our tokenizers vocab size\n",
    "max_words = 25000\n",
    "\n",
    "# create the tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "# Fit the tokenizer\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Create the sequences for each sentence, basically turning each word into its index position\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "index_word = tokenizer.index_word\n",
    "\n",
    "# # Limiting our sequence to only include 500 words\n",
    "max_length = 500\n",
    "\n",
    "# # Convert the sequences to all be the same length of 500\n",
    "X = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33c515bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 500, 32)           800000    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16000)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               2048128   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,848,773\n",
      "Trainable params: 2,848,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This creates the Neural Network\n",
    "model = Sequential() \n",
    "\n",
    "# This embedding layer basically will automatically create the word2vec vectors based on your text data.\n",
    "model.add( Embedding(max_words, 32, input_length=max_length) ) \n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c06f31ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 1.1922 - accuracy: 0.4863 - val_loss: 1.0873 - val_accuracy: 0.5610\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6754 - accuracy: 0.7466 - val_loss: 1.2162 - val_accuracy: 0.5282\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.1883 - accuracy: 0.9463 - val_loss: 1.6325 - val_accuracy: 0.5165\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0678 - accuracy: 0.9852 - val_loss: 1.7948 - val_accuracy: 0.5153\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 16s 21ms/step - loss: 0.0431 - accuracy: 0.9892 - val_loss: 1.9694 - val_accuracy: 0.5120\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.0295 - accuracy: 0.9914 - val_loss: 2.2023 - val_accuracy: 0.5002\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 2.1691 - val_accuracy: 0.5130\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0189 - accuracy: 0.9923 - val_loss: 2.4854 - val_accuracy: 0.5090\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0179 - accuracy: 0.9924 - val_loss: 2.7773 - val_accuracy: 0.4900\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0173 - accuracy: 0.9920 - val_loss: 3.0109 - val_accuracy: 0.4963\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0368 - accuracy: 0.9869 - val_loss: 3.6104 - val_accuracy: 0.4755\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0477 - accuracy: 0.9817 - val_loss: 3.6058 - val_accuracy: 0.4970\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0161 - accuracy: 0.9923 - val_loss: 3.8822 - val_accuracy: 0.4947\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.0121 - accuracy: 0.9931 - val_loss: 3.8825 - val_accuracy: 0.4935\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0117 - accuracy: 0.9937 - val_loss: 3.9797 - val_accuracy: 0.4748\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.0127 - accuracy: 0.9926 - val_loss: 4.1503 - val_accuracy: 0.4905\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 16s 21ms/step - loss: 0.0137 - accuracy: 0.9927 - val_loss: 4.1530 - val_accuracy: 0.4905\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.0138 - accuracy: 0.9934 - val_loss: 3.9225 - val_accuracy: 0.4885\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0151 - accuracy: 0.9925 - val_loss: 4.3321 - val_accuracy: 0.4785\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.0194 - accuracy: 0.9919 - val_loss: 5.1969 - val_accuracy: 0.4705\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X, y, \n",
    "                 validation_split=0.2, \n",
    "                 epochs=20, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55c4e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e0084e3d00>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the acccuracy\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(hist.history['accuracy'], label='training accuracy',color='blue')\n",
    "plt.plot(hist.history['val_accuracy'], label = 'validation accuracy',color='red', linestyle='dashed')\n",
    "plt.title('Accuracy by Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.ylim([0.9, 1.1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f36ab9",
   "metadata": {},
   "source": [
    "# RNN Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9a063163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 500, 32)           800000    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825,157\n",
      "Trainable params: 825,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_words, 32, input_length=max_length))\n",
    "\n",
    "model.add(layers.LSTM(64, dropout=0.1))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b8714e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss='categorical_crossentropy'\n",
    "optimizer='adam'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6cd518a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 97s 120ms/step - loss: 1.6102 - accuracy: 0.2046 - val_loss: 1.6100 - val_accuracy: 0.1963\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 103s 129ms/step - loss: 1.6141 - accuracy: 0.1999 - val_loss: 1.6151 - val_accuracy: 0.1963\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 122s 152ms/step - loss: 1.6110 - accuracy: 0.2021 - val_loss: 1.6123 - val_accuracy: 0.2085\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 146s 183ms/step - loss: 1.6059 - accuracy: 0.2039 - val_loss: 1.6034 - val_accuracy: 0.2163\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 129s 162ms/step - loss: 1.6062 - accuracy: 0.2006 - val_loss: 1.6043 - val_accuracy: 0.2040\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 153s 192ms/step - loss: 1.6155 - accuracy: 0.1980 - val_loss: 1.6052 - val_accuracy: 0.2165\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 136s 170ms/step - loss: 1.5965 - accuracy: 0.2161 - val_loss: 1.4403 - val_accuracy: 0.3490\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 137s 171ms/step - loss: 1.3169 - accuracy: 0.3732 - val_loss: 1.2994 - val_accuracy: 0.4022\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 128s 160ms/step - loss: 1.2465 - accuracy: 0.4099 - val_loss: 1.2712 - val_accuracy: 0.4070\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 133s 167ms/step - loss: 1.1941 - accuracy: 0.4367 - val_loss: 1.2765 - val_accuracy: 0.4098\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 122s 153ms/step - loss: 1.1315 - accuracy: 0.4619 - val_loss: 1.2968 - val_accuracy: 0.4105\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 127s 159ms/step - loss: 1.0789 - accuracy: 0.4875 - val_loss: 1.3435 - val_accuracy: 0.4017\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 125s 156ms/step - loss: 1.0336 - accuracy: 0.5113 - val_loss: 1.4020 - val_accuracy: 0.3947\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 123s 154ms/step - loss: 0.9956 - accuracy: 0.5199 - val_loss: 1.3904 - val_accuracy: 0.4190\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 128s 160ms/step - loss: 0.9633 - accuracy: 0.5508 - val_loss: 1.4683 - val_accuracy: 0.4128\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 126s 158ms/step - loss: 0.9454 - accuracy: 0.5651 - val_loss: 1.4671 - val_accuracy: 0.4218\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 128s 161ms/step - loss: 0.9239 - accuracy: 0.5852 - val_loss: 1.5236 - val_accuracy: 0.4193\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 132s 164ms/step - loss: 0.8917 - accuracy: 0.6036 - val_loss: 1.5242 - val_accuracy: 0.4252\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 138s 173ms/step - loss: 0.8617 - accuracy: 0.6237 - val_loss: 1.5314 - val_accuracy: 0.4190\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 115s 144ms/step - loss: 0.8291 - accuracy: 0.6420 - val_loss: 1.5657 - val_accuracy: 0.4202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e00bcb9c90>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, validation_split=0.2, \n",
    "                 epochs=20, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f91ed51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
