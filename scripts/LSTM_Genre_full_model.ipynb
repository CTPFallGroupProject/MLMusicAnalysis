{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b0df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression as log \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn import metrics    \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c666d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63af967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Dense, Input, Flatten, Bidirectional\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b975c31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop        57357\n",
       "Rock       26756\n",
       "Country     7440\n",
       "Rap         5959\n",
       "R&B         4773\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labeled_lyrics_w_genres.csv')\n",
    "df.head()\n",
    "\n",
    "df = df.drop(columns = ['Unnamed: 0','Unnamed: 0.1'],axis = 1)\n",
    "\n",
    "df_dropped = df[(df['genre'] == 'No_genre') | (df['genre'] == 'Non-Music')].index\n",
    "df.drop(df_dropped, inplace=True, axis='index')\n",
    "\n",
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ca26461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = \"\"\n",
    "\n",
    "cond = df['genre'] == 'Pop'\n",
    "df_pop = df[cond]\n",
    "df_pop = df_pop[0:2000]\n",
    "\n",
    "cond = df['genre'] == 'Rock'\n",
    "df_rock = df[cond]\n",
    "df_rock = df_rock[0:2000]\n",
    "df_rock.shape\n",
    "\n",
    "cond = df['genre'] == 'Country'\n",
    "df_country = df[cond]\n",
    "df_country = df_country[0:2000]\n",
    "df_country.shape\n",
    "\n",
    "cond = df['genre'] == 'Rap'\n",
    "df_rap = df[cond]\n",
    "df_rap = df_rap[0:2000]\n",
    "df_rap.shape\n",
    "\n",
    "cond = df['genre'] == 'R&B'\n",
    "df_r_b = df[cond]\n",
    "df_r_b = df_r_b[0:2000]\n",
    "df_r_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd04ebd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_pop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_balanced \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mdf_pop\u001b[49m, df_rock, df_country, df_rap, df_r_b], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_balanced[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_pop' is not defined"
     ]
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_pop, df_rock, df_country, df_rap, df_r_b], axis = 0)\n",
    "\n",
    "df_balanced['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd4439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove numbers\n",
    "def remove_numbers(input):\n",
    "    input = word_tokenize(input)\n",
    "    without_sw = [word for word in input \n",
    "                  if word.isalpha()]\n",
    "    return ' '.join(without_sw)\n",
    "\n",
    "# 1. function that makes all text lowercase.\n",
    "def make_lowercase(test_string):\n",
    "    return test_string.lower()\n",
    "\n",
    "# 2. function that removes all punctuation. \n",
    "def remove_punc(test_string):\n",
    "    test_string = re.sub(r'[^\\w\\s]', '', test_string)\n",
    "    return test_string\n",
    "\n",
    "# 3. function that removes all stopwords.\n",
    "def remove_sw(input):\n",
    "    input = word_tokenize(input)\n",
    "    without_sw = [word for word in input \n",
    "                  if word not in stopwords]\n",
    "    return ' '.join(without_sw)\n",
    "\n",
    "# 4. function to break words into their stem words\n",
    "def stem_words(input):\n",
    "    stemming = PorterStemmer()\n",
    "    tokenized_words = word_tokenize(input)\n",
    "    \n",
    "    stemmed_words = [stemming.stem(word) for word in tokenized_words]\n",
    "    return ' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6785341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "\n",
    "def text_processing_pipeline(a_string):\n",
    "    a_string = make_lowercase(a_string)\n",
    "    a_string = remove_numbers(a_string)\n",
    "    a_string = remove_punc(a_string)\n",
    "    a_string = remove_sw(a_string)\n",
    "    #a_string = stem_words(a_string)\n",
    "    return a_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a548c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b350d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['seq_clean'] = df_balanced['seq'].apply(lambda x: text_processing_pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cdd1865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "      <th>seq_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>No, no\\r\\nI ain't ever trapped out the bando\\r...</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>0.626</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>ai ever trapped bando oh lord get wrong know c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>The drinks go down and smoke goes up, I feel m...</td>\n",
       "      <td>Live Till We Die</td>\n",
       "      <td>0.630</td>\n",
       "      <td>Pop</td>\n",
       "      <td>drinks go smoke goes feel got let go cares get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>She don't live on planet Earth no more\\r\\nShe ...</td>\n",
       "      <td>The Otherside</td>\n",
       "      <td>0.240</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>live planet earth found love venus word said n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>Trippin' off that Grigio, mobbin', lights low\\...</td>\n",
       "      <td>Pinot</td>\n",
       "      <td>0.536</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>trippin grigio mobbin lights low trippin grigi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>I see a midnight panther, so gallant and so br...</td>\n",
       "      <td>Shadows &amp; Diamonds</td>\n",
       "      <td>0.371</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>see midnight panther gallant brave found found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145245</th>\n",
       "      <td>Michael Franti</td>\n",
       "      <td>Heavy medicine\\r\\nYa see my eyes are feeling r...</td>\n",
       "      <td>Ganja Babe</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Pop</td>\n",
       "      <td>heavy medicine ya see eyes feeling red bringin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145246</th>\n",
       "      <td>Rodriguez</td>\n",
       "      <td>The generals hate holidays\\r\\nOthers shoot up ...</td>\n",
       "      <td>Sandrevan Lullaby - Lifestyles</td>\n",
       "      <td>0.327</td>\n",
       "      <td>Rock</td>\n",
       "      <td>generals hate holidays others shoot chase sun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145247</th>\n",
       "      <td>Darryl Worley</td>\n",
       "      <td>Girl tonight it's pouring down on us\\r\\nIt's b...</td>\n",
       "      <td>Hard Rain Don't Last</td>\n",
       "      <td>0.406</td>\n",
       "      <td>Country</td>\n",
       "      <td>girl tonight pouring us building long yeah dar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145248</th>\n",
       "      <td>UB40</td>\n",
       "      <td>[Chorus]\\r\\nThere's a rat in me kitchen what a...</td>\n",
       "      <td>Rat in Mi Kitchen</td>\n",
       "      <td>0.826</td>\n",
       "      <td>Pop</td>\n",
       "      <td>chorus rat kitchen gon na rat kitchen gon na g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145249</th>\n",
       "      <td>Elvis Costello</td>\n",
       "      <td>The party's over\\r\\nYour time is up\\r\\nYou've ...</td>\n",
       "      <td>It's Time</td>\n",
       "      <td>0.585</td>\n",
       "      <td>Rock</td>\n",
       "      <td>party time last pointless teardrop washed brok...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102285 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                                                seq  \\\n",
       "0         Elijah Blake  No, no\\r\\nI ain't ever trapped out the bando\\r...   \n",
       "1         Elijah Blake  The drinks go down and smoke goes up, I feel m...   \n",
       "2         Elijah Blake  She don't live on planet Earth no more\\r\\nShe ...   \n",
       "3         Elijah Blake  Trippin' off that Grigio, mobbin', lights low\\...   \n",
       "4         Elijah Blake  I see a midnight panther, so gallant and so br...   \n",
       "...                ...                                                ...   \n",
       "145245  Michael Franti  Heavy medicine\\r\\nYa see my eyes are feeling r...   \n",
       "145246       Rodriguez  The generals hate holidays\\r\\nOthers shoot up ...   \n",
       "145247   Darryl Worley  Girl tonight it's pouring down on us\\r\\nIt's b...   \n",
       "145248            UB40  [Chorus]\\r\\nThere's a rat in me kitchen what a...   \n",
       "145249  Elvis Costello  The party's over\\r\\nYour time is up\\r\\nYou've ...   \n",
       "\n",
       "                                  song  label    genre  \\\n",
       "0                             Everyday  0.626      R&B   \n",
       "1                     Live Till We Die  0.630      Pop   \n",
       "2                        The Otherside  0.240      R&B   \n",
       "3                                Pinot  0.536      R&B   \n",
       "4                   Shadows & Diamonds  0.371      R&B   \n",
       "...                                ...    ...      ...   \n",
       "145245                      Ganja Babe  0.712      Pop   \n",
       "145246  Sandrevan Lullaby - Lifestyles  0.327     Rock   \n",
       "145247            Hard Rain Don't Last  0.406  Country   \n",
       "145248               Rat in Mi Kitchen  0.826      Pop   \n",
       "145249                       It's Time  0.585     Rock   \n",
       "\n",
       "                                                seq_clean  \n",
       "0       ai ever trapped bando oh lord get wrong know c...  \n",
       "1       drinks go smoke goes feel got let go cares get...  \n",
       "2       live planet earth found love venus word said n...  \n",
       "3       trippin grigio mobbin lights low trippin grigi...  \n",
       "4       see midnight panther gallant brave found found...  \n",
       "...                                                   ...  \n",
       "145245  heavy medicine ya see eyes feeling red bringin...  \n",
       "145246  generals hate holidays others shoot chase sun ...  \n",
       "145247  girl tonight pouring us building long yeah dar...  \n",
       "145248  chorus rat kitchen gon na rat kitchen gon na g...  \n",
       "145249  party time last pointless teardrop washed brok...  \n",
       "\n",
       "[102285 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f44752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Each night I lie in my bed \\r\\nAnd I think about it \\r\\nOh my dark friend \\r\\nCan you give me an answer \\r\\n\\r\\nThe people that we love\\r\\nWe cannot understand \\r\\nEvery day the people that we love are hurt \\r\\nThe people who we love \\r\\nAnd cannot understand\\r\\nWe cannot understand \\r\\n\\r\\nDo you believe we're the children of a God\\r\\nDo you believe \\r\\nOr do you believe we're left here all alone\\r\\nDo you believe \\r\\n\\r\\nI have this question\\r\\nWhat is it for \\r\\nThis poor life \\r\\nWe live down here\\r\\n\\r\\nIs there a power all above \\r\\nA person so called God \\r\\nSo called God \\r\\nWho plans our life \\r\\nOr is it our free will \\r\\nThe creator of our life \\r\\nAre we responsible \\r\\n\\r\\nThe people that we love\\r\\nWe cannot understand \\r\\nEvery day the people that we love are hurt \\r\\nThe people who we love \\r\\nAnd cannot understand\\r\\nWe cannot understand \\r\\n\\r\\nDo you believe we're the children of a God\\r\\nDo you believe \\r\\nOr do you believe we're left here all alone\\r\\nDo you believe\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.iloc[9][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1442d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df_balanced['genre'] = labelencoder.fit_transform(df_balanced['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f50e174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Country', 'Pop', 'R&B', 'Rap', 'Rock'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "305d48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced['seq_clean']\n",
    "\n",
    "y = df_balanced['genre'].values\n",
    "#y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f748db4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 145246 is out of bounds for axis 0 with size 102285",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m145246\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 145246 is out of bounds for axis 0 with size 102285"
     ]
    }
   ],
   "source": [
    "y[145246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcad6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting our tokenizers vocab size\n",
    "max_words = 10000\n",
    "\n",
    "# create the tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "# Fit the tokenizer\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Create the sequences for each sentence, basically turning each word into its index position\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "index_word = tokenizer.index_word\n",
    "\n",
    "# # Limiting our sequence to only include 500 words\n",
    "max_length = 300\n",
    "\n",
    "# # Convert the sequences to all be the same length of 500\n",
    "X = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "841dff87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102285, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1abf865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the Neural Network\n",
    "model = Sequential() \n",
    "\n",
    "model.add( Embedding(max_words, 32, input_length=max_length) ) \n",
    "#model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(350, activation='relu'))\n",
    "#model.add(Dense(400, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y,\n",
    "         # validation_data=(X_test,y_test),\n",
    "          validation_split= 0.2,\n",
    "          epochs=20,\n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54b7af0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500, 300)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X, y, \n",
    "                 validation_split=0.2, \n",
    "                 epochs=20, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca728a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the acccuracy\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(hist.history['accuracy'], label='training accuracy',color='blue')\n",
    "plt.plot(hist.history['val_accuracy'], label = 'validation accuracy',color='red', linestyle='dashed')\n",
    "plt.title('Accuracy by Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.ylim([0.9, 1.1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc81e86",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2316f879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 32)           320000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345,157\n",
      "Trainable params: 345,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, 32, input_length=max_length))\n",
    "\n",
    "model.add(layers.LSTM(64, dropout=0.1))\n",
    "#model.add(layers.LSTM(74, dropout=0.1))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83c7c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss='categorical_crossentropy'\n",
    "optimizer='adam'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f918905",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ce1fecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1279/1279 [==============================] - 195s 151ms/step - loss: 1.1167 - accuracy: 0.5773 - val_loss: 1.0516 - val_accuracy: 0.5878\n",
      "Epoch 2/20\n",
      "1279/1279 [==============================] - 214s 168ms/step - loss: 1.0305 - accuracy: 0.5943 - val_loss: 1.0242 - val_accuracy: 0.5955\n",
      "Epoch 3/20\n",
      "1279/1279 [==============================] - 244s 191ms/step - loss: 1.0095 - accuracy: 0.5986 - val_loss: 1.0189 - val_accuracy: 0.5966\n",
      "Epoch 4/20\n",
      "1279/1279 [==============================] - 243s 190ms/step - loss: 1.0014 - accuracy: 0.5996 - val_loss: 1.0385 - val_accuracy: 0.5943\n",
      "Epoch 5/20\n",
      "1279/1279 [==============================] - 250s 196ms/step - loss: 1.0062 - accuracy: 0.5981 - val_loss: 1.0345 - val_accuracy: 0.5966\n",
      "Epoch 6/20\n",
      "1279/1279 [==============================] - 251s 197ms/step - loss: 0.9727 - accuracy: 0.6007 - val_loss: 0.9982 - val_accuracy: 0.5976\n",
      "Epoch 7/20\n",
      "1279/1279 [==============================] - 247s 193ms/step - loss: 0.9483 - accuracy: 0.6019 - val_loss: 1.0002 - val_accuracy: 0.5963\n",
      "Epoch 8/20\n",
      "1279/1279 [==============================] - 266s 208ms/step - loss: 0.9233 - accuracy: 0.6073 - val_loss: 0.9835 - val_accuracy: 0.5966\n",
      "Epoch 9/20\n",
      "1279/1279 [==============================] - 243s 190ms/step - loss: 0.9037 - accuracy: 0.6175 - val_loss: 0.9842 - val_accuracy: 0.6006\n",
      "Epoch 10/20\n",
      "1279/1279 [==============================] - 246s 192ms/step - loss: 0.8905 - accuracy: 0.6248 - val_loss: 0.9872 - val_accuracy: 0.5934\n",
      "Epoch 11/20\n",
      "1279/1279 [==============================] - 243s 190ms/step - loss: 0.8757 - accuracy: 0.6336 - val_loss: 0.9818 - val_accuracy: 0.5991\n",
      "Epoch 12/20\n",
      "1279/1279 [==============================] - 243s 190ms/step - loss: 0.8554 - accuracy: 0.6412 - val_loss: 0.9844 - val_accuracy: 0.5904\n",
      "Epoch 13/20\n",
      "1279/1279 [==============================] - 240s 188ms/step - loss: 0.8420 - accuracy: 0.6497 - val_loss: 0.9888 - val_accuracy: 0.5952\n",
      "Epoch 14/20\n",
      "1279/1279 [==============================] - 234s 183ms/step - loss: 0.8239 - accuracy: 0.6568 - val_loss: 0.9973 - val_accuracy: 0.5888\n",
      "Epoch 15/20\n",
      "1279/1279 [==============================] - 244s 191ms/step - loss: 0.8041 - accuracy: 0.6678 - val_loss: 1.0004 - val_accuracy: 0.5908\n",
      "Epoch 16/20\n",
      "1279/1279 [==============================] - 240s 188ms/step - loss: 0.7826 - accuracy: 0.6812 - val_loss: 1.0091 - val_accuracy: 0.5932\n",
      "Epoch 17/20\n",
      "1279/1279 [==============================] - 233s 182ms/step - loss: 0.7582 - accuracy: 0.6963 - val_loss: 1.0344 - val_accuracy: 0.5703\n",
      "Epoch 18/20\n",
      "1279/1279 [==============================] - 225s 176ms/step - loss: 0.7370 - accuracy: 0.7108 - val_loss: 1.0417 - val_accuracy: 0.5700\n",
      "Epoch 19/20\n",
      "1279/1279 [==============================] - 246s 193ms/step - loss: 0.7147 - accuracy: 0.7247 - val_loss: 1.0753 - val_accuracy: 0.5589\n",
      "Epoch 20/20\n",
      "1279/1279 [==============================] - 243s 190ms/step - loss: 0.6917 - accuracy: 0.7382 - val_loss: 1.0850 - val_accuracy: 0.5659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d710255270>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = callbacks.EarlyStopping(monitor='val_loss',patience = 2,restore_best_weights=True)\n",
    "model.fit(X_train,y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          epochs=20,\n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc78f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM_Genre_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8acdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "loaded_model = keras.models.load_model('LSTM_Genre_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a98cb6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences([input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06800440",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputX = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "434b6040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = np.argmax(model.predict(inputX))\n",
    "encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "adb51320",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = '''I never stay in one place too long\n",
    "A dirt road's singing me a siren song\n",
    "I gotta find a field\n",
    "I need to spin my wheels\n",
    "I got a hankering for four wide tires\n",
    "And I can't help it it's the way I'm wired\n",
    "'Fore you get too close\n",
    "Boy you need to know\n",
    "I got a heart like a truck\n",
    "It's been drug through the mud\n",
    "Runs on dreams and gasoline\n",
    "And that ole highway holds the key\n",
    "It's got a lead foot down when it's leaving\n",
    "Lord knows it's taken a hell of a beating\n",
    "A little bit of love is all that it's needing\n",
    "But it's good as it is tough\n",
    "I got a heart like a truck\n",
    "There ain't no breaking when I throw it in drive\n",
    "Don't always keep it in between the lines\n",
    "If you're ready for a ride pedal down state of mind\n",
    "Boy I tell you what\n",
    "You better buckle up'''\n",
    "\n",
    "input = text_processing_pipeline(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e8bd086",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences([input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "373aeed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputX = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551274c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "083d3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7739bc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Country'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = labelencoder.inverse_transform([encode])\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa75cd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pop'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9d2a00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "350/350 [==============================] - 84s 233ms/step - loss: 1.2026 - accuracy: 0.3594 - val_loss: 4.9718 - val_accuracy: 0.2637\n",
      "Epoch 2/20\n",
      "350/350 [==============================] - 84s 239ms/step - loss: 1.1624 - accuracy: 0.3721 - val_loss: 6.1713 - val_accuracy: 0.2053\n",
      "Epoch 3/20\n",
      "350/350 [==============================] - 81s 232ms/step - loss: 1.1199 - accuracy: 0.3844 - val_loss: 5.5289 - val_accuracy: 0.1707\n",
      "Epoch 4/20\n",
      "350/350 [==============================] - 82s 235ms/step - loss: 1.1180 - accuracy: 0.3917 - val_loss: 5.6625 - val_accuracy: 0.2780\n",
      "Epoch 5/20\n",
      "350/350 [==============================] - 80s 230ms/step - loss: 1.0437 - accuracy: 0.4120 - val_loss: 5.7731 - val_accuracy: 0.2827\n",
      "Epoch 6/20\n",
      "350/350 [==============================] - 80s 227ms/step - loss: 1.0163 - accuracy: 0.4563 - val_loss: 6.4619 - val_accuracy: 0.2607\n",
      "Epoch 7/20\n",
      "350/350 [==============================] - 80s 229ms/step - loss: 0.9655 - accuracy: 0.5154 - val_loss: 6.6143 - val_accuracy: 0.2690\n",
      "Epoch 8/20\n",
      "350/350 [==============================] - 82s 235ms/step - loss: 0.9131 - accuracy: 0.5533 - val_loss: 7.1371 - val_accuracy: 0.2550\n",
      "Epoch 9/20\n",
      "350/350 [==============================] - 92s 263ms/step - loss: 0.8566 - accuracy: 0.5990 - val_loss: 7.3828 - val_accuracy: 0.2470\n",
      "Epoch 10/20\n",
      "350/350 [==============================] - 90s 257ms/step - loss: 0.8771 - accuracy: 0.5771 - val_loss: 7.2398 - val_accuracy: 0.2643\n",
      "Epoch 11/20\n",
      "350/350 [==============================] - 95s 272ms/step - loss: 0.7972 - accuracy: 0.6490 - val_loss: 7.3427 - val_accuracy: 0.2740\n",
      "Epoch 12/20\n",
      "350/350 [==============================] - 91s 261ms/step - loss: 0.7692 - accuracy: 0.6710 - val_loss: 7.3640 - val_accuracy: 0.2493\n",
      "Epoch 13/20\n",
      "350/350 [==============================] - 86s 246ms/step - loss: 0.7260 - accuracy: 0.6993 - val_loss: 7.6308 - val_accuracy: 0.2667\n",
      "Epoch 14/20\n",
      "350/350 [==============================] - 82s 234ms/step - loss: 0.6942 - accuracy: 0.7160 - val_loss: 7.7047 - val_accuracy: 0.2480\n",
      "Epoch 15/20\n",
      "350/350 [==============================] - 80s 230ms/step - loss: 0.6585 - accuracy: 0.7416 - val_loss: 7.9630 - val_accuracy: 0.2683\n",
      "Epoch 16/20\n",
      "350/350 [==============================] - 86s 246ms/step - loss: 0.6273 - accuracy: 0.7580 - val_loss: 7.9933 - val_accuracy: 0.2617\n",
      "Epoch 17/20\n",
      "350/350 [==============================] - 90s 257ms/step - loss: 0.6022 - accuracy: 0.7767 - val_loss: 8.0207 - val_accuracy: 0.2693\n",
      "Epoch 18/20\n",
      "350/350 [==============================] - 85s 243ms/step - loss: 0.5804 - accuracy: 0.7853 - val_loss: 8.1714 - val_accuracy: 0.2437\n",
      "Epoch 19/20\n",
      "350/350 [==============================] - 99s 284ms/step - loss: 0.5685 - accuracy: 0.7946 - val_loss: 8.3068 - val_accuracy: 0.2717\n",
      "Epoch 20/20\n",
      "350/350 [==============================] - 88s 252ms/step - loss: 0.5274 - accuracy: 0.8146 - val_loss: 8.2406 - val_accuracy: 0.2683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17d21d96aa0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, \n",
    "          validation_split=0.3, \n",
    "          epochs=20, \n",
    "          batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62b1eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 25ms/step - loss: 2.5711 - accuracy: 0.3650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.571089267730713, 0.36500000953674316]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6fe93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 300, 32)           800000    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              49664     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 850,309\n",
      "Trainable params: 850,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_words, 32, input_length=max_length))\n",
    "\n",
    "model.add(Bidirectional(layers.LSTM(64, dropout=0.1)))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0cbb8feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "350/350 [==============================] - 59s 162ms/step - loss: 1.2516 - accuracy: 0.3513 - val_loss: 5.6959 - val_accuracy: 0.2323\n",
      "Epoch 2/20\n",
      "350/350 [==============================] - 56s 161ms/step - loss: 0.9678 - accuracy: 0.5696 - val_loss: 6.0586 - val_accuracy: 0.2297\n",
      "Epoch 3/20\n",
      "292/350 [========================>.....] - ETA: 7s - loss: 0.6671 - accuracy: 0.7368"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, \n",
    "          validation_split=0.3, \n",
    "          epochs=20, \n",
    "          batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58c31d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1955/3580 [===============>..............] - ETA: 51:12 - loss: 1.0843 - accuracy: 0.5807"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, \n",
    "          validation_split=0.3, \n",
    "          epochs=20, \n",
    "          batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4634ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 32)           1120000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,145,157\n",
      "Trainable params: 1,145,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_words, 32, input_length=max_length))\n",
    "\n",
    "model.add(layers.LSTM(64, dropout=0.1))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c622e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss='categorical_crossentropy'\n",
    "optimizer='adam'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59f99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4092/4092 [==============================] - 457s 111ms/step - loss: 1.0690 - accuracy: 0.5868 - val_loss: 1.0478 - val_accuracy: 0.5950\n",
      "Epoch 2/20\n",
      "4092/4092 [==============================] - 421s 103ms/step - loss: 1.0227 - accuracy: 0.5974 - val_loss: 1.0398 - val_accuracy: 0.5959\n",
      "Epoch 3/20\n",
      "4092/4092 [==============================] - 516s 126ms/step - loss: 1.0048 - accuracy: 0.5987 - val_loss: 1.0187 - val_accuracy: 0.5974\n",
      "Epoch 4/20\n",
      "4092/4092 [==============================] - 470s 115ms/step - loss: 0.9888 - accuracy: 0.6006 - val_loss: 1.0109 - val_accuracy: 0.5975\n",
      "Epoch 5/20\n",
      "4092/4092 [==============================] - 543s 133ms/step - loss: 0.9803 - accuracy: 0.6015 - val_loss: 1.0021 - val_accuracy: 0.5971\n",
      "Epoch 6/20\n",
      "4092/4092 [==============================] - 475s 116ms/step - loss: 0.9398 - accuracy: 0.6091 - val_loss: 0.9805 - val_accuracy: 0.6005\n",
      "Epoch 7/20\n",
      "4092/4092 [==============================] - 576s 141ms/step - loss: 0.9075 - accuracy: 0.6293 - val_loss: 0.9730 - val_accuracy: 0.6020\n",
      "Epoch 8/20\n",
      "4092/4092 [==============================] - 495s 121ms/step - loss: 0.8734 - accuracy: 0.6482 - val_loss: 0.9794 - val_accuracy: 0.6005\n",
      "Epoch 9/20\n",
      "4092/4092 [==============================] - 497s 122ms/step - loss: 0.8348 - accuracy: 0.6669 - val_loss: 0.9853 - val_accuracy: 0.5961\n",
      "Epoch 10/20\n",
      "4092/4092 [==============================] - 474s 116ms/step - loss: 0.7891 - accuracy: 0.6871 - val_loss: 1.0217 - val_accuracy: 0.5815\n",
      "Epoch 11/20\n",
      "4092/4092 [==============================] - 426s 104ms/step - loss: 0.7380 - accuracy: 0.7123 - val_loss: 1.0402 - val_accuracy: 0.5786\n",
      "Epoch 12/20\n",
      "4092/4092 [==============================] - 476s 116ms/step - loss: 0.6854 - accuracy: 0.7386 - val_loss: 1.0705 - val_accuracy: 0.5832\n",
      "Epoch 13/20\n",
      "4092/4092 [==============================] - 449s 110ms/step - loss: 0.6339 - accuracy: 0.7609 - val_loss: 1.1238 - val_accuracy: 0.5804\n",
      "Epoch 14/20\n",
      "4092/4092 [==============================] - 452s 111ms/step - loss: 0.5816 - accuracy: 0.7854 - val_loss: 1.1962 - val_accuracy: 0.5675\n",
      "Epoch 15/20\n",
      "3313/4092 [=======================>......] - ETA: 1:31 - loss: 0.5329 - accuracy: 0.8037"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, \n",
    "          validation_split=0.2, \n",
    "          epochs=20, \n",
    "          batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd10e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7abeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "251c0f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 300, 32)           1120000   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 300, 64)           24832     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,178,181\n",
      "Trainable params: 1,178,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_words, 32, input_length=max_length))\n",
    "\n",
    "model.add(layers.LSTM(64, dropout=0.1,  return_sequences=True))\n",
    "model.add(layers.LSTM(64, dropout=0.1))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16cefa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss='categorical_crossentropy'\n",
    "optimizer='adam'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8c00789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4092/4092 [==============================] - 938s 228ms/step - loss: 1.0581 - accuracy: 0.5894 - val_loss: 1.0476 - val_accuracy: 0.5914\n",
      "Epoch 2/20\n",
      "4092/4092 [==============================] - 912s 223ms/step - loss: 1.0223 - accuracy: 0.5981 - val_loss: 1.0404 - val_accuracy: 0.5930\n",
      "Epoch 3/20\n",
      "4092/4092 [==============================] - 830s 203ms/step - loss: 0.9995 - accuracy: 0.5996 - val_loss: 1.0077 - val_accuracy: 0.5962\n",
      "Epoch 4/20\n",
      "4092/4092 [==============================] - 917s 224ms/step - loss: 0.9555 - accuracy: 0.6018 - val_loss: 0.9938 - val_accuracy: 0.5937\n",
      "Epoch 5/20\n",
      "4092/4092 [==============================] - 1128s 276ms/step - loss: 0.9120 - accuracy: 0.6217 - val_loss: 0.9677 - val_accuracy: 0.5967\n",
      "Epoch 6/20\n",
      "4092/4092 [==============================] - 954s 233ms/step - loss: 0.8678 - accuracy: 0.6437 - val_loss: 0.9649 - val_accuracy: 0.5919\n",
      "Epoch 7/20\n",
      "4092/4092 [==============================] - 926s 226ms/step - loss: 0.8199 - accuracy: 0.6665 - val_loss: 0.9652 - val_accuracy: 0.5975\n",
      "Epoch 8/20\n",
      "4092/4092 [==============================] - 1041s 254ms/step - loss: 0.7712 - accuracy: 0.6949 - val_loss: 0.9843 - val_accuracy: 0.5961\n",
      "Epoch 9/20\n",
      "4092/4092 [==============================] - 963s 235ms/step - loss: 0.7197 - accuracy: 0.7215 - val_loss: 1.0085 - val_accuracy: 0.5891\n",
      "Epoch 10/20\n",
      "4092/4092 [==============================] - 930s 227ms/step - loss: 0.6660 - accuracy: 0.7452 - val_loss: 1.0565 - val_accuracy: 0.5823\n",
      "Epoch 11/20\n",
      "4092/4092 [==============================] - 909s 222ms/step - loss: 0.6164 - accuracy: 0.7679 - val_loss: 1.1027 - val_accuracy: 0.5752\n",
      "Epoch 12/20\n",
      "4092/4092 [==============================] - 905s 221ms/step - loss: 0.5694 - accuracy: 0.7864 - val_loss: 1.1527 - val_accuracy: 0.5850\n",
      "Epoch 13/20\n",
      "4092/4092 [==============================] - 900s 220ms/step - loss: 0.5256 - accuracy: 0.8048 - val_loss: 1.2297 - val_accuracy: 0.5616\n",
      "Epoch 14/20\n",
      "4092/4092 [==============================] - 897s 219ms/step - loss: 0.4885 - accuracy: 0.8199 - val_loss: 1.2795 - val_accuracy: 0.5683\n",
      "Epoch 15/20\n",
      "4092/4092 [==============================] - 917s 224ms/step - loss: 0.4549 - accuracy: 0.8323 - val_loss: 1.3463 - val_accuracy: 0.5663\n",
      "Epoch 16/20\n",
      "4092/4092 [==============================] - 922s 225ms/step - loss: 0.4264 - accuracy: 0.8425 - val_loss: 1.4370 - val_accuracy: 0.5671\n",
      "Epoch 17/20\n",
      "4092/4092 [==============================] - 929s 227ms/step - loss: 0.4013 - accuracy: 0.8516 - val_loss: 1.4723 - val_accuracy: 0.5578\n",
      "Epoch 18/20\n",
      "4092/4092 [==============================] - 965s 236ms/step - loss: 0.3784 - accuracy: 0.8609 - val_loss: 1.5286 - val_accuracy: 0.5623\n",
      "Epoch 19/20\n",
      "4092/4092 [==============================] - 1011s 247ms/step - loss: 0.3549 - accuracy: 0.8704 - val_loss: 1.5719 - val_accuracy: 0.5437\n",
      "Epoch 20/20\n",
      "4092/4092 [==============================] - 942s 230ms/step - loss: 0.3350 - accuracy: 0.8772 - val_loss: 1.5899 - val_accuracy: 0.5586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28cb2c6f970>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, \n",
    "          validation_split=0.2, \n",
    "          epochs=20, \n",
    "          batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6036a046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 400, 32)           1280000   \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 400, 64)           24832     \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              66048     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,371,525\n",
      "Trainable params: 1,371,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(max_words, 32, input_length=max_length))\n",
    "\n",
    "model.add(layers.LSTM(64, dropout=0.1,  return_sequences=True))\n",
    "model.add(Bidirectional(layers.LSTM(64, dropout=0.1)))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15e504c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss='categorical_crossentropy'\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=loss, optimizer= opt, metrics=metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b48c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4092/4092 [==============================] - 1535s 374ms/step - loss: 1.0613 - accuracy: 0.5853 - val_loss: 1.0200 - val_accuracy: 0.5943\n",
      "Epoch 2/20\n",
      "4092/4092 [==============================] - 1645s 402ms/step - loss: 0.9780 - accuracy: 0.5965 - val_loss: 0.9990 - val_accuracy: 0.5956\n",
      "Epoch 3/20\n",
      "4092/4092 [==============================] - 1353s 331ms/step - loss: 0.9362 - accuracy: 0.6054 - val_loss: 0.9868 - val_accuracy: 0.5976\n",
      "Epoch 4/20\n",
      "4092/4092 [==============================] - 1391s 340ms/step - loss: 0.9082 - accuracy: 0.6177 - val_loss: 0.9862 - val_accuracy: 0.5930\n",
      "Epoch 5/20\n",
      "4092/4092 [==============================] - 4807s 1s/step - loss: 0.8803 - accuracy: 0.6308 - val_loss: 0.9919 - val_accuracy: 0.5900\n",
      "Epoch 6/20\n",
      "4092/4092 [==============================] - 1499s 366ms/step - loss: 0.8550 - accuracy: 0.6437 - val_loss: 0.9951 - val_accuracy: 0.5900\n",
      "Epoch 7/20\n",
      "4092/4092 [==============================] - 1325s 324ms/step - loss: 0.8329 - accuracy: 0.6551 - val_loss: 0.9992 - val_accuracy: 0.5940\n",
      "Epoch 8/20\n",
      "4092/4092 [==============================] - 2540s 621ms/step - loss: 0.8121 - accuracy: 0.6671 - val_loss: 1.0172 - val_accuracy: 0.5863\n",
      "Epoch 9/20\n",
      "2243/4092 [===============>..............] - ETA: 19:22 - loss: 0.7868 - accuracy: 0.6806"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, \n",
    "          validation_split=0.2, \n",
    "          epochs=20, \n",
    "          batch_size=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
