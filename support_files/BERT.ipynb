{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eda1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502a242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression as log \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn import metrics    \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571bcf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop        57357\n",
       "Rock       26756\n",
       "Country     7440\n",
       "Rap         5959\n",
       "R&B         4773\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labeled_lyrics_w_genres.csv')\n",
    "df.head()\n",
    "\n",
    "df = df.drop(columns = ['Unnamed: 0','Unnamed: 0.1'],axis = 1)\n",
    "\n",
    "df_dropped = df[(df['genre'] == 'No_genre') | (df['genre'] == 'Non-Music')].index\n",
    "df.drop(df_dropped, inplace=True, axis='index')\n",
    "\n",
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c2dd7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = \"\"\n",
    "\n",
    "cond = df['genre'] == 'Pop'\n",
    "df_pop = df[cond]\n",
    "df_pop = df_pop[0:500]\n",
    "\n",
    "cond = df['genre'] == 'Rock'\n",
    "df_rock = df[cond]\n",
    "df_rock = df_rock[0:500]\n",
    "df_rock.shape\n",
    "\n",
    "cond = df['genre'] == 'Country'\n",
    "df_country = df[cond]\n",
    "df_country = df_country[0:500]\n",
    "df_country.shape\n",
    "\n",
    "cond = df['genre'] == 'Rap'\n",
    "df_rap = df[cond]\n",
    "df_rap = df_rap[0:500]\n",
    "df_rap.shape\n",
    "\n",
    "cond = df['genre'] == 'R&B'\n",
    "df_r_b = df[cond]\n",
    "df_r_b = df_r_b[0:500]\n",
    "df_r_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a21f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop        500\n",
       "Rock       500\n",
       "Country    500\n",
       "Rap        500\n",
       "R&B        500\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_pop, df_rock, df_country, df_rap, df_r_b], axis = 0)\n",
    "\n",
    "df_balanced['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef3bc703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove numbers\n",
    "def remove_numbers(input):\n",
    "    input = word_tokenize(input)\n",
    "    without_sw = [word for word in input \n",
    "                  if word.isalpha()]\n",
    "    return ' '.join(without_sw)\n",
    "\n",
    "# 1. function that makes all text lowercase.\n",
    "def make_lowercase(test_string):\n",
    "    return test_string.lower()\n",
    "\n",
    "# 2. function that removes all punctuation. \n",
    "def remove_punc(test_string):\n",
    "    test_string = re.sub(r'[^\\w\\s]', '', test_string)\n",
    "    return test_string\n",
    "\n",
    "# 3. function that removes all stopwords.\n",
    "def remove_sw(input):\n",
    "    input = word_tokenize(input)\n",
    "    without_sw = [word for word in input \n",
    "                  if word not in stopwords]\n",
    "    return ' '.join(without_sw)\n",
    "\n",
    "# 4. function to break words into their stem words\n",
    "def stem_words(input):\n",
    "    stemming = PorterStemmer()\n",
    "    tokenized_words = word_tokenize(input)\n",
    "    \n",
    "    stemmed_words = [stemming.stem(word) for word in tokenized_words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "\n",
    "def lemmatize_words(input):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenized_words = word_tokenize(input)\n",
    "    \n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tokenized_words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6670b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "\n",
    "def text_processing_pipeline(a_string):\n",
    "    a_string = make_lowercase(a_string)\n",
    "    a_string = remove_numbers(a_string)\n",
    "    a_string = remove_punc(a_string)\n",
    "    a_string = remove_sw(a_string)\n",
    "    #a_string = stem_words(a_string)\n",
    "    return a_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "068a3073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['seq_clean'] = df_balanced['seq'].apply(lambda x: text_processing_pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c91bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>DJ Jazzy Jeff &amp; the Fresh Prince</td>\n",
       "      <td>Here's a little story 'bout a Friday night,\\r\\...</td>\n",
       "      <td>Code Red</td>\n",
       "      <td>0.755</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10936</th>\n",
       "      <td>Ryan Adams</td>\n",
       "      <td>Well I went down to Houston and I stopped in S...</td>\n",
       "      <td>Oh My Sweet Carolina</td>\n",
       "      <td>0.306</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6922</th>\n",
       "      <td>Gym Class Heroes</td>\n",
       "      <td>This is not novelty\\r\\nThis is nothing delicat...</td>\n",
       "      <td>Biters Block</td>\n",
       "      <td>0.616</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>LL Cool J</td>\n",
       "      <td>I know a honey named Millie, raised out in Phi...</td>\n",
       "      <td>After School</td>\n",
       "      <td>0.793</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>The Brand New Heavies</td>\n",
       "      <td>Together we got love, we got peace\\r\\nTogether...</td>\n",
       "      <td>Day by Day</td>\n",
       "      <td>0.670</td>\n",
       "      <td>R&amp;B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 artist  \\\n",
       "4866   DJ Jazzy Jeff & the Fresh Prince   \n",
       "10936                        Ryan Adams   \n",
       "6922                   Gym Class Heroes   \n",
       "3088                          LL Cool J   \n",
       "4169              The Brand New Heavies   \n",
       "\n",
       "                                                     seq  \\\n",
       "4866   Here's a little story 'bout a Friday night,\\r\\...   \n",
       "10936  Well I went down to Houston and I stopped in S...   \n",
       "6922   This is not novelty\\r\\nThis is nothing delicat...   \n",
       "3088   I know a honey named Millie, raised out in Phi...   \n",
       "4169   Together we got love, we got peace\\r\\nTogether...   \n",
       "\n",
       "                       song  label    genre  \n",
       "4866               Code Red  0.755      Rap  \n",
       "10936  Oh My Sweet Carolina  0.306  Country  \n",
       "6922           Biters Block  0.616      Rap  \n",
       "3088           After School  0.793      Rap  \n",
       "4169             Day by Day  0.670      R&B  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec617e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df,column_name):\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df\n",
    "df_balanced = create_dummies(df_balanced,\"genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ec0b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_balanced['genre']= label_encoder.fit_transform(df_balanced['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e000398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "4    500\n",
       "0    500\n",
       "3    500\n",
       "2    500\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "668ddf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_features = df_balanced.columns[5:11] \n",
    "y_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb86bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced['seq']\n",
    "y = df_balanced['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0dec73c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        1\n",
       "7        1\n",
       "8        1\n",
       "9        1\n",
       "10       1\n",
       "        ..\n",
       "18179    2\n",
       "18185    2\n",
       "18214    2\n",
       "18217    2\n",
       "18257    2\n",
       "Name: genre, Length: 2500, dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "164d6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50469018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba7ad87",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e993ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f4773b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07b2a2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_hub.keras_layer.KerasLayer at 0x24a2aab53c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "20508c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.74583364, -0.3479747 , -0.09725112, ...,  0.11525007,\n",
       "        -0.68303424,  0.85167116],\n",
       "       [-0.8676579 , -0.2502348 ,  0.42193842, ...,  0.25290197,\n",
       "        -0.6358296 ,  0.91478306]], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentense_embedding(sentenses):\n",
    "    preprocessed_text = bert_preprocess(sentenses)\n",
    "    vector = bert_encoder(preprocessed_text)['pooled_output']\n",
    "    return vector\n",
    "\n",
    "get_sentense_embedding([\n",
    "    \"500$ discount\",\n",
    "    'I eat mango, sweet mango'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7dc3e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = get_sentense_embedding([\n",
    "    \"banana\",\n",
    "    \"mango\",\n",
    "    'television',\n",
    "    \"Elon Musk\",\n",
    "    \"Tesla\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3d9d52d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9801978]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity([e[3]], [e[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db461349",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6547ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural Network Layers\n",
    "l = Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = Dense(1, activation='softmax', name=\"output\")(l)\n",
    "\n",
    "# Final model\n",
    "\n",
    "model = tf.keras.Model(inputs=[text_input], outputs=[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "777cc2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'default': (None,   109482241   ['keras_layer[0][0]',            \n",
      "                                768),                             'keras_layer[0][1]',            \n",
      "                                 'encoder_outputs':               'keras_layer[0][2]']            \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768)}                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ee7713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c93460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 2027s 40s/step - loss: -10.5205 - accuracy: 0.1944 - val_loss: -20.1620 - val_accuracy: 0.2025\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 1831s 37s/step - loss: -29.0440 - accuracy: 0.1944 - val_loss: -38.7876 - val_accuracy: 0.2025\n",
      "Epoch 3/10\n",
      " 3/50 [>.............................] - ETA: 29:20 - loss: -38.2153 - accuracy: 0.1667"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17bc727f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_train\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
